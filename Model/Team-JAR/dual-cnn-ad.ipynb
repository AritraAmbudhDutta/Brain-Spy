{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":12270226,"datasetId":7732223,"databundleVersionId":12819443},{"sourceType":"datasetVersion","sourceId":12289243,"datasetId":7739436,"databundleVersionId":12840594}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nibabel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:49:52.380593Z","iopub.execute_input":"2025-06-26T13:49:52.380877Z","iopub.status.idle":"2025-06-26T13:49:57.267079Z","shell.execute_reply.started":"2025-06-26T13:49:52.380856Z","shell.execute_reply":"2025-06-26T13:49:57.266409Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (25.0)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.13.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->nibabel) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22->nibabel) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22->nibabel) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nmetadata = '/kaggle/input/mri-images/ADNI1_Complete_1Yr_1.5T_6_20_2025.csv'\nmeta = pd.read_csv(metadata)\nmeta.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:49:57.268598Z","iopub.execute_input":"2025-06-26T13:49:57.269113Z","iopub.status.idle":"2025-06-26T13:49:57.600007Z","shell.execute_reply.started":"2025-06-26T13:49:57.269087Z","shell.execute_reply":"2025-06-26T13:49:57.599405Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  Image Data ID     Subject Group Sex  Age Visit Modality  \\\n0       I112538  941_S_1311   MCI   M   70   m12      MRI   \n1        I97341  941_S_1311   MCI   M   70   m06      MRI   \n2        I97327  941_S_1311   MCI   M   69    sc      MRI   \n3        I75150  941_S_1202    CN   M   78   m06      MRI   \n4       I105437  941_S_1202    CN   M   79   m12      MRI   \n\n                                  Description       Type   Acq Date Format  \\\n0    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  6/01/2008  NiFTI   \n1  MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  9/27/2007  NiFTI   \n2    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  3/02/2007  NiFTI   \n3    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  8/24/2007  NiFTI   \n4    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  2/28/2008  NiFTI   \n\n   Downloaded  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Data ID</th>\n      <th>Subject</th>\n      <th>Group</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Visit</th>\n      <th>Modality</th>\n      <th>Description</th>\n      <th>Type</th>\n      <th>Acq Date</th>\n      <th>Format</th>\n      <th>Downloaded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I112538</td>\n      <td>941_S_1311</td>\n      <td>MCI</td>\n      <td>M</td>\n      <td>70</td>\n      <td>m12</td>\n      <td>MRI</td>\n      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n      <td>Processed</td>\n      <td>6/01/2008</td>\n      <td>NiFTI</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I97341</td>\n      <td>941_S_1311</td>\n      <td>MCI</td>\n      <td>M</td>\n      <td>70</td>\n      <td>m06</td>\n      <td>MRI</td>\n      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n      <td>Processed</td>\n      <td>9/27/2007</td>\n      <td>NiFTI</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I97327</td>\n      <td>941_S_1311</td>\n      <td>MCI</td>\n      <td>M</td>\n      <td>69</td>\n      <td>sc</td>\n      <td>MRI</td>\n      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n      <td>Processed</td>\n      <td>3/02/2007</td>\n      <td>NiFTI</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I75150</td>\n      <td>941_S_1202</td>\n      <td>CN</td>\n      <td>M</td>\n      <td>78</td>\n      <td>m06</td>\n      <td>MRI</td>\n      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n      <td>Processed</td>\n      <td>8/24/2007</td>\n      <td>NiFTI</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I105437</td>\n      <td>941_S_1202</td>\n      <td>CN</td>\n      <td>M</td>\n      <td>79</td>\n      <td>m12</td>\n      <td>MRI</td>\n      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n      <td>Processed</td>\n      <td>2/28/2008</td>\n      <td>NiFTI</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# meta.iloc[:, 1].shape\n\nfor name in range(len(meta.iloc[:, 1])):\n    print(meta.iloc[name, 1])\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:49:57.600760Z","iopub.execute_input":"2025-06-26T13:49:57.601003Z","iopub.status.idle":"2025-06-26T13:49:57.605484Z","shell.execute_reply.started":"2025-06-26T13:49:57.600970Z","shell.execute_reply":"2025-06-26T13:49:57.604765Z"}},"outputs":[{"name":"stdout","text":"941_S_1311\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\ndata_dir = '/kaggle/input/mri-preprocessed/pre_processed_files1'\n\nfiles = [f for f in os.listdir(data_dir) if f.endswith('.nii')]\n\nprint(len(files))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:49:57.606797Z","iopub.execute_input":"2025-06-26T13:49:57.606992Z","iopub.status.idle":"2025-06-26T13:49:57.740608Z","shell.execute_reply.started":"2025-06-26T13:49:57.606977Z","shell.execute_reply":"2025-06-26T13:49:57.740069Z"}},"outputs":[{"name":"stdout","text":"445\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"file_ids = []\nfor file in files:\n    parts = file.split('_')\n    file_str = parts[2] + '_' + parts[3] + '_' + parts[4]\n    file_ids.append(file_str)\n\n# len(file_ids)\n\ny = []\n# for subject in range(len(meta.iloc[:, 1])):\n#     for file_id in file_ids:\n#         if (file_id == meta.iloc[subject, 1]):\n#             y.append([meta.iloc[subject, 1], meta.iloc[subject, 2]])\n\nfor file_id in file_ids:\n    for subject in range(len(meta.iloc[:, 1])):\n        if (file_id == meta.iloc[subject, 1]):\n            y.append([meta.iloc[subject, 1], meta.iloc[subject, 2]])\n            break\n        continue\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:49:57.741173Z","iopub.execute_input":"2025-06-26T13:49:57.741357Z","iopub.status.idle":"2025-06-26T13:50:04.909149Z","shell.execute_reply.started":"2025-06-26T13:49:57.741335Z","shell.execute_reply":"2025-06-26T13:50:04.908416Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"file_ids[:5], y[:5]\n# file_ids contain the id of the preprocessed files\n# y contains the [id, target] for them","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:50:04.910359Z","iopub.execute_input":"2025-06-26T13:50:04.910621Z","iopub.status.idle":"2025-06-26T13:50:04.915763Z","shell.execute_reply.started":"2025-06-26T13:50:04.910603Z","shell.execute_reply":"2025-06-26T13:50:04.915119Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(['023_S_0887', '136_S_0300', '022_S_1394', '005_S_0610', '036_S_0813'],\n [['023_S_0887', 'MCI'],\n  ['136_S_0300', 'AD'],\n  ['022_S_1394', 'MCI'],\n  ['005_S_0610', 'CN'],\n  ['036_S_0813', 'CN']])"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"y[10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:50:04.916408Z","iopub.execute_input":"2025-06-26T13:50:04.916690Z","iopub.status.idle":"2025-06-26T13:50:04.933294Z","shell.execute_reply.started":"2025-06-26T13:50:04.916668Z","shell.execute_reply":"2025-06-26T13:50:04.932622Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['029_S_1215', 'MCI']"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# visualising data\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nnii_file = os.path.join(data_dir, files[10])\nimg = nib.load(nii_file)\ndata = img.get_fdata()\n\nprint(\"Shape:\", data.shape)\n\ndef show_slices(slices):\n    fig, axes = plt.subplots(1, len(slices), figsize=(15, 5))\n    for i, slice in enumerate(slices):\n        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n    plt.tight_layout()\n    plt.show()\n\n# Select central slices from axial, sagittal, coronal planes\nsagittal = data[data.shape[0] // 2, :, :]\ncoronal  = data[:, data.shape[1] // 2, :]\naxial    = data[:, :, data.shape[2] // 2]\n\nshow_slices([sagittal, coronal, axial])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T12:41:36.137931Z","iopub.status.idle":"2025-06-26T12:41:36.138286Z","shell.execute_reply.started":"2025-06-26T12:41:36.138119Z","shell.execute_reply":"2025-06-26T12:41:36.138136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"import nibabel as nib\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Directory path\ndata_dir = \"/kaggle/input/mri-preprocessed/pre_processed_files1\"\nnii_list = os.listdir(data_dir)\n\nmax_axial_shape = (0, 0)\n\nfor filename in nii_list:\n    path = os.path.join(data_dir, filename)\n    nii_img = nib.load(path)\n    data = nii_img.get_fdata()\n    \n    axial_shape = data.shape[:2]\n\n    if np.prod(axial_shape) > np.prod(max_axial_shape):\n        max_axial_shape = axial_shape\n\nprint(f\"Axial plane shape: {max_axial_shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:50:04.934095Z","iopub.execute_input":"2025-06-26T13:50:04.934376Z","iopub.status.idle":"2025-06-26T13:52:10.946235Z","shell.execute_reply.started":"2025-06-26T13:50:04.934357Z","shell.execute_reply":"2025-06-26T13:52:10.945510Z"}},"outputs":[{"name":"stdout","text":"Axial plane shape: (184, 256)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def pad_to_shape(img, target_shape):\n    h, w = img.shape\n    H, W = target_shape\n    pad_top = (H - h) // 2\n    pad_bottom = H - h - pad_top\n    pad_left = (W - w) // 2\n    pad_right = W - w - pad_left\n    return np.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')\n\n\npadded_images = []\ny_ordered = []\n\n\nfor file in os.listdir(data_dir):\n    if file.endswith('.nii') or file.endswith('.nii.gz'):\n        parts = file.split('_')\n        file_str = parts[2] + '_' + parts[3] + '_' + parts[4]\n\n        for i in range(len(y)):\n            if file_str == y[i][0]:\n                y_ordered.append([file_str, y[i][1]])\n                break\n    \n        nii_path = os.path.join(data_dir, file)\n        data = nib.load(nii_path).get_fdata()\n        \n        axial = data[:, :, data.shape[2] // 2]    # axial central slice\n        padded = pad_to_shape(axial, max_axial_shape)\n        \n        padded_images.append(padded)\n        # labels.append(label_map[label])\n\nX = np.array(padded_images).reshape(-1, max_axial_shape[0], max_axial_shape[1], 1)\n\nprint(f\"X shape: {X.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:52:10.947604Z","iopub.execute_input":"2025-06-26T13:52:10.947984Z","iopub.status.idle":"2025-06-26T13:52:25.018843Z","shell.execute_reply.started":"2025-06-26T13:52:10.947949Z","shell.execute_reply":"2025-06-26T13:52:25.018143Z"}},"outputs":[{"name":"stdout","text":"X shape: (445, 184, 256, 1)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"len(y_ordered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:52:25.019693Z","iopub.execute_input":"2025-06-26T13:52:25.020458Z","iopub.status.idle":"2025-06-26T13:52:25.024669Z","shell.execute_reply.started":"2025-06-26T13:52:25.020430Z","shell.execute_reply":"2025-06-26T13:52:25.024108Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"445"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# label encodings\n\ny_data = []\nfor id_, label in y_ordered:\n    if label == 'MCI':\n        y_data.append(1)\n    elif label == 'AD':\n        y_data.append(2)\n    elif label == 'CN':\n        y_data.append(0)\n    else:\n        print(f\"Label: {label}\")\n        \ny_data = np.array(y_data)\ny_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:52:25.025366Z","iopub.execute_input":"2025-06-26T13:52:25.025625Z","iopub.status.idle":"2025-06-26T13:52:25.043921Z","shell.execute_reply.started":"2025-06-26T13:52:25.025603Z","shell.execute_reply":"2025-06-26T13:52:25.043223Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(445,)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# y_ordered -> contains [image_id, label]\n# X -> (445, 184, 256, 1) axial slices\n# y_data -> contains labels in the same order as the X values {0, 1, 2}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:55:42.508503Z","iopub.execute_input":"2025-06-26T13:55:42.509177Z","iopub.status.idle":"2025-06-26T13:55:47.496239Z","shell.execute_reply.started":"2025-06-26T13:55:42.509154Z","shell.execute_reply":"2025-06-26T13:55:47.495502Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"class cnn1(nn.Module):\n    def __init__(self, kernel_size=3, dropout_rate=0.2, in_channels=1):\n        super(cnn1, self).__init__()\n\n        self.K = kernel_size\n        self.in_channels = in_channels\n        self.dropout_rate = dropout_rate\n\n        self.net = nn.Sequential(\n            nn.Conv2d(self.in_channels, 16, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n\n            nn.Conv2d(16, 16, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(16, 64, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n\n            nn.Conv2d(64, 64, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(64, 256, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Dropout2d(self.dropout_rate),\n            nn.Flatten(),\n            nn.Linear(188416, 128) # TODO: Check this line\n        )\n\n    def forward(self, x):\n        x = self.net(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:55:49.451513Z","iopub.execute_input":"2025-06-26T13:55:49.451961Z","iopub.status.idle":"2025-06-26T13:55:49.458639Z","shell.execute_reply.started":"2025-06-26T13:55:49.451936Z","shell.execute_reply":"2025-06-26T13:55:49.457873Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class cnn2(nn.Module):\n    def __init__(self, kernel_size=5, dropout_rate=0.2, in_channels=1):\n        super(cnn2, self).__init__()\n\n        self.K = kernel_size\n        self.in_channels = in_channels\n        self.dropout_rate = dropout_rate\n\n        self.net = nn.Sequential(\n            nn.Conv2d(self.in_channels, 32, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n\n            nn.Conv2d(32, 32, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(32, 128, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n\n            nn.Conv2d(128, 128, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(128, 512, kernel_size=self.K, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.Dropout2d(self.dropout_rate),\n            nn.Flatten(),\n            nn.Linear(296960, 128)\n        )\n\n    def forward(self, x):\n        x = self.net(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:55:52.925931Z","iopub.execute_input":"2025-06-26T13:55:52.926165Z","iopub.status.idle":"2025-06-26T13:55:52.932256Z","shell.execute_reply.started":"2025-06-26T13:55:52.926150Z","shell.execute_reply":"2025-06-26T13:55:52.931574Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class ADNet(nn.Module):\n    def __init__(self, input_dim=224, dropout_rate=0.2, in_channels=1, n_labels=3):\n        super(ADNet, self).__init__()\n\n        self.input_dim = input_dim\n        self.dropout_rate = dropout_rate\n        self.in_channels = in_channels\n        self.n_labels = n_labels\n\n        self.cnn1 = cnn1(dropout_rate=self.dropout_rate, in_channels=self.in_channels)\n        self.cnn2 = cnn2(dropout_rate=self.dropout_rate, in_channels=self.in_channels)\n\n        self.classifier = nn.Sequential(\n            nn.Linear(128 + 128, 128),\n            nn.ReLU(),\n            nn.Dropout(self.dropout_rate),\n            nn.Linear(128, self.n_labels)   # final layer for binary classification\n        )\n\n    def forward(self, x):\n        x1 = self.cnn1(x)   # shape: (B, 128)\n        x2 = self.cnn2(x)   # shape: (B, 128)\n\n        x = torch.cat((x1, x2), dim=1)  # concatenate features from both CNNs, shape: (B, 256)\n        x = self.classifier(x)          # shape: (B, 1)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:55:53.189837Z","iopub.execute_input":"2025-06-26T13:55:53.190066Z","iopub.status.idle":"2025-06-26T13:55:53.195279Z","shell.execute_reply.started":"2025-06-26T13:55:53.190050Z","shell.execute_reply":"2025-06-26T13:55:53.194767Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# testing dimensions\nmodel = ADNet()\ninput_tensor = torch.randn(8, 1, 184, 256)  # batch of 8 single-channel images\noutput = model(input_tensor)               # output shape: (8, n_labels)\nprint(output.shape)  # should print torch.Size([8, 1]) for binary classification\nprint(model)  # print the model architecture","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:55:56.458746Z","iopub.execute_input":"2025-06-26T13:55:56.459006Z","iopub.status.idle":"2025-06-26T13:55:58.763454Z","shell.execute_reply.started":"2025-06-26T13:55:56.458987Z","shell.execute_reply":"2025-06-26T13:55:58.762729Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 3])\nADNet(\n  (cnn1): cnn1(\n    (net): Sequential(\n      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (5): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (6): ReLU()\n      (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (8): ReLU()\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (10): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (11): ReLU()\n      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (14): ReLU()\n      (15): Dropout2d(p=0.2, inplace=False)\n      (16): Flatten(start_dim=1, end_dim=-1)\n      (17): Linear(in_features=188416, out_features=128, bias=True)\n    )\n  )\n  (cnn2): cnn2(\n    (net): Sequential(\n      (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (5): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n      (6): ReLU()\n      (7): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n      (8): ReLU()\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (10): Conv2d(128, 512, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n      (11): ReLU()\n      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (14): ReLU()\n      (15): Dropout2d(p=0.2, inplace=False)\n      (16): Flatten(start_dim=1, end_dim=-1)\n      (17): Linear(in_features=296960, out_features=128, bias=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=256, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=128, out_features=3, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# dataset class\nfrom torch.utils.data import Dataset\n\nclass mri_data(Dataset):\n    def __init__(self, X, y):\n        self.X = X.astype(np.float32)\n        self.y = y.astype(np.int64)\n\n        # Reshape: (N, H, W, 1) → (N, 1, H, W) for PyTorch conv layers\n        if self.X.ndim == 4 and self.X.shape[-1] == 1:\n            self.X = np.transpose(self.X, (0, 3, 1, 2))  # (N, 1, H, W)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        img = torch.from_numpy(self.X[idx])\n        label = torch.tensor(self.y[idx], dtype=torch.long)\n        return img, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:58:01.524307Z","iopub.execute_input":"2025-06-26T13:58:01.525026Z","iopub.status.idle":"2025-06-26T13:58:01.530221Z","shell.execute_reply.started":"2025-06-26T13:58:01.525002Z","shell.execute_reply":"2025-06-26T13:58:01.529494Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\n# Wrap into Dataset\ndataset = mri_data(X, y_data)\n\n# Split into train and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_ds, batch_size=3, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=3, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:58:03.975616Z","iopub.execute_input":"2025-06-26T13:58:03.976264Z","iopub.status.idle":"2025-06-26T13:58:04.020885Z","shell.execute_reply.started":"2025-06-26T13:58:03.976243Z","shell.execute_reply":"2025-06-26T13:58:04.020308Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# training\nmodel = ADNet().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:58:06.580162Z","iopub.execute_input":"2025-06-26T13:58:06.580687Z","iopub.status.idle":"2025-06-26T13:58:10.049933Z","shell.execute_reply.started":"2025-06-26T13:58:06.580665Z","shell.execute_reply":"2025-06-26T13:58:10.049198Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# train loop\ndef train_epoch(model, dataloader, optimizer, criterion):\n  model.train()\n  current_loss = 0.0\n  correct, total = 0, 0\n\n  for inputs, targets in dataloader:\n    inputs, targets = inputs.to(device), targets.to(device)\n\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n\n    current_loss += loss.item() * inputs.size(0)\n    _, predicted = outputs.max(1)\n    correct += predicted.eq(targets).sum().item()\n    total += targets.size(0)\n\n  avg_loss = current_loss / total\n  accuracy = correct / total\n\n  return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T14:01:22.944640Z","iopub.execute_input":"2025-06-26T14:01:22.945140Z","iopub.status.idle":"2025-06-26T14:01:22.949941Z","shell.execute_reply.started":"2025-06-26T14:01:22.945115Z","shell.execute_reply":"2025-06-26T14:01:22.949247Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# evaluation loop\ndef evaluate(model, dataloader, criterion):\n  model.eval()\n  current_loss = 0.0\n  correct, total = 0, 0\n\n  with torch.no_grad():\n    for inputs, targets in dataloader:\n      inputs, targets = inputs.to(device), targets.to(device)\n      outputs = model(inputs)\n      loss = criterion(outputs, targets)\n\n      current_loss += loss.item() * inputs.size(0)\n      _, predicted = outputs.max(1)\n      correct += predicted.eq(targets).sum().item()\n      total += targets.size(0)\n\n  avg_loss = current_loss / total\n  accuracy = correct / total\n\n  return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T14:01:58.547913Z","iopub.execute_input":"2025-06-26T14:01:58.548467Z","iopub.status.idle":"2025-06-26T14:01:58.553282Z","shell.execute_reply.started":"2025-06-26T14:01:58.548443Z","shell.execute_reply":"2025-06-26T14:01:58.552629Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# training loop\ndef train_model(model, train_loader, val_loader, epochs=10):\n  for epoch in range(epochs):\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)\n\n    print(f\"Epoch {epoch+1}/{epochs}\")\n    print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc*100:.2f}%\")\n    print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc*100:.2f}%\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:58:33.454213Z","iopub.execute_input":"2025-06-26T13:58:33.454769Z","iopub.status.idle":"2025-06-26T13:58:33.459025Z","shell.execute_reply.started":"2025-06-26T13:58:33.454746Z","shell.execute_reply":"2025-06-26T13:58:33.458196Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T14:02:01.487183Z","iopub.execute_input":"2025-06-26T14:02:01.487531Z","iopub.status.idle":"2025-06-26T14:04:08.060500Z","shell.execute_reply.started":"2025-06-26T14:02:01.487511Z","shell.execute_reply":"2025-06-26T14:04:08.059829Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n  Train Loss: 1.0350, Accuracy: 53.09%\n  Val   Loss: 1.3111, Accuracy: 46.07%\n\nEpoch 2/10\n  Train Loss: 1.0040, Accuracy: 57.58%\n  Val   Loss: 1.5778, Accuracy: 48.31%\n\nEpoch 3/10\n  Train Loss: 0.8402, Accuracy: 63.76%\n  Val   Loss: 1.4986, Accuracy: 48.31%\n\nEpoch 4/10\n  Train Loss: 0.6551, Accuracy: 75.00%\n  Val   Loss: 1.3711, Accuracy: 48.31%\n\nEpoch 5/10\n  Train Loss: 0.4651, Accuracy: 82.58%\n  Val   Loss: 1.8211, Accuracy: 40.45%\n\nEpoch 6/10\n  Train Loss: 0.3552, Accuracy: 87.92%\n  Val   Loss: 1.6741, Accuracy: 47.19%\n\nEpoch 7/10\n  Train Loss: 0.1522, Accuracy: 95.51%\n  Val   Loss: 2.3766, Accuracy: 43.82%\n\nEpoch 8/10\n  Train Loss: 0.1334, Accuracy: 94.38%\n  Val   Loss: 2.1093, Accuracy: 42.70%\n\nEpoch 9/10\n  Train Loss: 0.0600, Accuracy: 98.88%\n  Val   Loss: 2.4408, Accuracy: 46.07%\n\nEpoch 10/10\n  Train Loss: 0.0390, Accuracy: 98.88%\n  Val   Loss: 2.7412, Accuracy: 47.19%\n\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}