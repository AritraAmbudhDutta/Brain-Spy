{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12269782,"sourceType":"datasetVersion","datasetId":7731899},{"sourceId":12281460,"sourceType":"datasetVersion","datasetId":7739889},{"sourceId":12289617,"sourceType":"datasetVersion","datasetId":7745419}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport nibabel as nib\nfrom scipy import ndimage\nimport torch\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:29.966694Z","iopub.execute_input":"2025-06-26T13:18:29.967054Z","iopub.status.idle":"2025-06-26T13:18:29.971197Z","shell.execute_reply.started":"2025-06-26T13:18:29.967026Z","shell.execute_reply":"2025-06-26T13:18:29.970557Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Exploratory Data Analysis\n# Realised that we have much more MCI Data, hence decided to move ahead with three category classification\ndf = pd.read_csv(\"/kaggle/input/adni-processed/ADNI1_Complete_1Yr_1.5T_6_20_2025.csv\")\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nColumns:\", df.columns.tolist())\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nLabel distribution:\")\nprint(df['Group'].value_counts())\nprint(f\"\\nUnique subjects: {df['Subject'].nunique()}\")\nprint(f\"Total scans: {len(df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:29.974016Z","iopub.execute_input":"2025-06-26T13:18:29.974209Z","iopub.status.idle":"2025-06-26T13:18:30.002167Z","shell.execute_reply.started":"2025-06-26T13:18:29.974196Z","shell.execute_reply":"2025-06-26T13:18:30.001333Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (2294, 12)\n\nColumns: ['Image Data ID', 'Subject', 'Group', 'Sex', 'Age', 'Visit', 'Modality', 'Description', 'Type', 'Acq Date', 'Format', 'Downloaded']\n\nFirst few rows:\n  Image Data ID     Subject Group Sex  Age Visit Modality  \\\n0       I112538  941_S_1311   MCI   M   70   m12      MRI   \n1        I97341  941_S_1311   MCI   M   70   m06      MRI   \n2        I97327  941_S_1311   MCI   M   69    sc      MRI   \n3        I75150  941_S_1202    CN   M   78   m06      MRI   \n4       I105437  941_S_1202    CN   M   79   m12      MRI   \n\n                                  Description       Type   Acq Date Format  \\\n0    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  6/01/2008  NiFTI   \n1  MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  9/27/2007  NiFTI   \n2    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  3/02/2007  NiFTI   \n3    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  8/24/2007  NiFTI   \n4    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  2/28/2008  NiFTI   \n\n   Downloaded  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  \n\nLabel distribution:\nGroup\nMCI    1113\nCN      705\nAD      476\nName: count, dtype: int64\n\nUnique subjects: 639\nTotal scans: 2294\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Understanding how the directory is structured\nbase_dir = \"/kaggle/input/adni-processed/ADNI1_Processed/ADNI1_Processed/\"\ndef explore_directory_structure(base_path, max_depth=3, current_depth=0):\n    items = []\n    if current_depth >= max_depth:\n        return items\n    for item in os.listdir(base_path)[:10]:  \n        item_path = os.path.join(base_path, item)\n        if os.path.isdir(item_path):\n            print(\"  \" * current_depth + f\"{item}/\")\n            items.extend(explore_directory_structure(item_path, max_depth, current_depth + 1))\n        else:\n            print(\"  \" * current_depth + f\"{item}\")\n            if item.endswith(('.nii', '.nii.gz')):\n                items.append(item_path)\n    return items\nnii_files = explore_directory_structure(base_dir)\nprint(f\"\\nFound {len(nii_files)} .nii files in sample\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:30.003248Z","iopub.execute_input":"2025-06-26T13:18:30.003439Z","iopub.status.idle":"2025-06-26T13:18:30.036598Z","shell.execute_reply.started":"2025-06-26T13:18:30.003425Z","shell.execute_reply":"2025-06-26T13:18:30.036105Z"}},"outputs":[{"name":"stdout","text":"133_S_0913/\n  I92637/\n    ADNI_133_S_0913_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20080225185003300_S35319_I92637_mni_norm.nii\n  I119636/\n    ADNI_133_S_0913_MR_MPR__GradWarp__B1_Correction__N3__Scaled_2_Br_20081008095615528_S35319_I119636_mni_norm.nii\n094_S_1090/\n  I63176/\n    ADNI_094_S_1090_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070731120023063_S23375_I63176_mni_norm.nii\n941_S_1194/\n  I75141/\n    ADNI_941_S_1194_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070925114520658_S38206_I75141_mni_norm.nii\n031_S_0618/\n  I91766/\n    ADNI_031_S_0618_MR_MPR-R__GradWarp__N3__Scaled_Br_20080223132226600_S24408_I91766_mni_norm.nii\n073_S_0312/\n  I39881/\n    ADNI_073_S_0312_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070213204740079_S15079_I39881_mni_norm.nii\n137_S_0669/\n  I66241/\n    ADNI_137_S_0669_MR_MPR__GradWarp__N3__Scaled_Br_20070808215314178_S27107_I66241_mni_norm.nii\n062_S_0535/\n  I50426/\n    ADNI_062_S_0535_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070424112744977_S14699_I50426_mni_norm.nii\n057_S_0464/\n  I62952/\n    ADNI_057_S_0464_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070730184032950_S25901_I62952_mni_norm.nii\n  I72414/\n    ADNI_057_S_0464_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070911103542442_S33667_I72414_mni_norm.nii\n002_S_0685/\n  I40683/\n    ADNI_002_S_0685_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070216235850690_S16309_I40683_mni_norm.nii\n036_S_0760/\n  I38652/\n    ADNI_036_S_0760_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070209144410346_S18264_I38652_mni_norm.nii\n\nFound 12 .nii files in sample\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Mapping the MRI Scans present in the ADNI_Processed directory to the respective metadata in the CSV file\n# Note that there has been limited mapping as the CSV file correponds to the entire ADNI Dataset, but I am working on a 10 gb subset\ndef simple_file_mapping(df, base_dir):\n    mapped_data = []\n    \n    for idx, row in df.iterrows():\n        subject_id = row['Subject']\n        image_id = row['Image Data ID']\n        group = row['Group']\n        \n        # Build path to subject directory\n        subject_dir = os.path.join(base_dir, subject_id)\n        \n        # Check if subject directory exists\n        if os.path.exists(subject_dir):\n            # Look through all subdirectories in the subject folder\n            for subfolder in os.listdir(subject_dir):\n                subfolder_path = os.path.join(subject_dir, subfolder)\n                \n                # Check if this subfolder matches our image_id or contains it\n                if os.path.isdir(subfolder_path):\n                    # Check if image_id matches subfolder name exactly\n                    if subfolder == image_id:\n                        nii_files = [f for f in os.listdir(subfolder_path) if f.endswith('.nii')]\n                        if nii_files:\n                            file_path = os.path.join(subfolder_path, nii_files[0])\n                            mapped_data.append({\n                                'subject_id': subject_id,\n                                'image_id': image_id,\n                                'group': group,\n                                'file_path': file_path\n                            })\n                            break  # Found the file, move to next CSV row\n                    \n                    # Also check if image_id is contained in the subfolder name\n                    elif image_id in subfolder:\n                        nii_files = [f for f in os.listdir(subfolder_path) if f.endswith('.nii')]\n                        if nii_files:\n                            file_path = os.path.join(subfolder_path, nii_files[0])\n                            mapped_data.append({\n                                'subject_id': subject_id,\n                                'image_id': image_id,\n                                'group': group,\n                                'file_path': file_path\n                            })\n                            break  # Found the file, move to next CSV row\n    \n    return pd.DataFrame(mapped_data)\n\nbase_dir = \"/kaggle/input/adni-processed/ADNI1_Processed/ADNI1_Processed\"\nmapped_df = simple_file_mapping(df, base_dir)\nprint(f\"Successfully mapped {len(mapped_df)} files\")\nprint(\"\\nSample mappings:\")\nfor i in range(min(3, len(mapped_df))):\n    row = mapped_df.iloc[i]\n    print(f\"Subject: {row['subject_id']} | Image ID: {row['image_id']} | Label: {row['group']}\")\n    print(f\"File: {row['file_path']}\")\n    print()\n\ndef check_scan_exists(image_id, mapped_df):\n    exists = image_id in mapped_df['image_id'].values\n    if exists:\n        scan_info = mapped_df[mapped_df['image_id'] == image_id].iloc[0]\n        print(f\"Found: {image_id} - Subject: {scan_info['subject_id']}, Label: {scan_info['group']}\")\n        print(f\"Path: {scan_info['file_path']}\")\n    else:\n        print(f\"Not found: {image_id}\")\n    return exists\n\n# Checking if a random MRI scan has been mapped\ncheck_scan_exists('I68056', mapped_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:30.152103Z","iopub.execute_input":"2025-06-26T13:18:30.152565Z","iopub.status.idle":"2025-06-26T13:18:31.521718Z","shell.execute_reply.started":"2025-06-26T13:18:30.152549Z","shell.execute_reply":"2025-06-26T13:18:31.521180Z"}},"outputs":[{"name":"stdout","text":"Successfully mapped 459 files\n\nSample mappings:\nSubject: 941_S_1311 | Image ID: I112538 | Label: MCI\nFile: /kaggle/input/adni-processed/ADNI1_Processed/ADNI1_Processed/941_S_1311/I112538/ADNI_941_S_1311_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20080703170241434_S51039_I112538_mni_norm.nii\n\nSubject: 941_S_1311 | Image ID: I97327 | Label: MCI\nFile: /kaggle/input/adni-processed/ADNI1_Processed/ADNI1_Processed/941_S_1311/I97327/ADNI_941_S_1311_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20080313130949784_S27408_I97327_mni_norm.nii\n\nSubject: 941_S_1197 | Image ID: I66462 | Label: CN\nFile: /kaggle/input/adni-processed/ADNI1_Processed/ADNI1_Processed/941_S_1197/I66462/ADNI_941_S_1197_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070809164131486_S25332_I66462_mni_norm.nii\n\nFound: I68056 - Subject: 021_S_0626, Label: MCI\nPath: /kaggle/input/adni-processed/ADNI1_Processed/ADNI1_Processed/021_S_0626/I68056/ADNI_021_S_0626_MR_MPR-R__GradWarp__N3__Scaled_Br_20070816132730116_S26663_I68056_mni_norm.nii\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# Understanding data distribution in my ADNI subset\nfiltered_df = mapped_df.copy()\nfiltered_df['label'] = filtered_df['group'].map({'CN': 0, 'MCI': 1, 'AD': 2})\n\nprint(f\"Three-class dataset: {len(filtered_df)} samples\")\nprint(\"Distribution:\")\nprint(filtered_df['group'].value_counts())\nprint(\"\\nPercentages:\")\nfor group, count in filtered_df['group'].value_counts().items():\n    print(f\"{group}: {count/len(filtered_df)*100:.1f}%\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:31.522756Z","iopub.execute_input":"2025-06-26T13:18:31.522992Z","iopub.status.idle":"2025-06-26T13:18:31.530604Z","shell.execute_reply.started":"2025-06-26T13:18:31.522976Z","shell.execute_reply":"2025-06-26T13:18:31.530006Z"}},"outputs":[{"name":"stdout","text":"Three-class dataset: 459 samples\nDistribution:\ngroup\nMCI    225\nCN     139\nAD      95\nName: count, dtype: int64\n\nPercentages:\nMCI: 49.0%\nCN: 30.3%\nAD: 20.7%\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Moving ahead with the train-test split based on unique subjects\n# I noted after some exploration that one medical subject might have multiple MRI scans, hence I ensured that all scans of one person are in the same set\nfrom sklearn.model_selection import train_test_split\nunique_subjects = filtered_df['subject_id'].unique()\nsubject_labels = filtered_df.groupby('subject_id')['group'].first()\nprint(f\"Unique subjects: {len(unique_subjects)}\")\ntrain_subjects, test_subjects = train_test_split(\n    unique_subjects,\n    test_size=0.2, \n    random_state=3,\n    stratify=subject_labels\n)\n\ntrain_subjects_list = list(train_subjects)\nsubject_labels_train = subject_labels[train_subjects_list]\n\nfinal_train_subjects, val_subjects = train_test_split(\n    train_subjects_list,\n    test_size=0.25,\n    random_state=69,\n    stratify=subject_labels_train\n)\n\ntrain_df = filtered_df[filtered_df['subject_id'].isin(final_train_subjects)].copy()\nval_df = filtered_df[filtered_df['subject_id'].isin(val_subjects)].copy()\ntest_df = filtered_df[filtered_df['subject_id'].isin(test_subjects)].copy()\n\nprint(f\"Training samples: {len(train_df)}\")\nprint(\"Training distribution:\")\nprint(train_df['group'].value_counts())\n\nprint(f\"\\nValidation samples: {len(val_df)}\")\nprint(\"Validation distribution:\")\nprint(val_df['group'].value_counts())\n\nprint(f\"\\nTest samples: {len(test_df)}\")\nprint(\"Test distribution:\")\nprint(test_df['group'].value_counts())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:31.531450Z","iopub.execute_input":"2025-06-26T13:18:31.531698Z","iopub.status.idle":"2025-06-26T13:18:31.554226Z","shell.execute_reply.started":"2025-06-26T13:18:31.531669Z","shell.execute_reply":"2025-06-26T13:18:31.553572Z"}},"outputs":[{"name":"stdout","text":"Unique subjects: 355\nTraining samples: 277\nTraining distribution:\ngroup\nMCI    136\nCN      87\nAD      54\nName: count, dtype: int64\n\nValidation samples: 97\nValidation distribution:\ngroup\nMCI    47\nCN     29\nAD     21\nName: count, dtype: int64\n\nTest samples: 85\nTest distribution:\ngroup\nMCI    42\nCN     23\nAD     20\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"class ADNIDataset(Dataset):\n    def __init__(self, df, target_shape=(128, 128, 128)):\n        self.df = df.reset_index(drop=True)\n        self.target_shape = target_shape\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Load MRI scan\n        img = nib.load(row['file_path'])\n        volume = img.get_fdata()\n        \n        # Preprocess following medical imaging best practices\n        volume = self.preprocess_volume(volume)\n        volume_tensor = torch.FloatTensor(volume).unsqueeze(0)  # Add channel dimension\n        \n        label = row['label']\n        return volume_tensor, label\n    \n    def preprocess_volume(self, volume):\n        # Intensity normalization (zero mean, unit variance)\n        volume = (volume - volume.mean()) / (volume.std() + 1e-8)\n        \n        # Clip extreme values\n        volume = np.clip(volume, -3, 3)\n        \n        # Resize to target shape for memory efficiency\n        if volume.shape != self.target_shape:\n            zoom_factors = [self.target_shape[i] / volume.shape[i] for i in range(3)]\n            volume = ndimage.zoom(volume, zoom_factors, order=1)\n        \n        return volume.astype(np.float32)\n\n# Create datasets\ntrain_dataset = ADNIDataset(train_df)\nval_dataset = ADNIDataset(val_df)\ntest_dataset = ADNIDataset(test_df)\n\n# Create data loaders with small batch sizes for 3D volumes\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:31.554908Z","iopub.execute_input":"2025-06-26T13:18:31.555130Z","iopub.status.idle":"2025-06-26T13:18:31.563953Z","shell.execute_reply.started":"2025-06-26T13:18:31.555108Z","shell.execute_reply":"2025-06-26T13:18:31.563270Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Loading and exploring the npz file with adnet weights\nnpz_path = \"/kaggle/input/adnet-weights/adnet.npz\"\ndata = np.load(npz_path, allow_pickle=True)\n\nprint(\"Keys in the .npz file:\")\nprint(data.files)\n\nprint(\"\\nDetailed information:\")\nfor key in data.files:\n    array = data[key]\n    print(f\"{key}: shape={array.shape}, dtype={array.dtype}\")\n    print(f\"  Value range: [{array.min():.6f}, {array.max():.6f}]\")\n    print(f\"  Mean: {array.mean():.6f}, Std: {array.std():.6f}\")\n    print()\n\nconv_weights = []\nconv_biases = []\nlinear_weights = []\nlinear_biases = []\n\nfor key in data.files:\n    shape = data[key].shape\n    if len(shape) == 5:  # Conv3D weights\n        conv_weights.append((key, shape))\n    elif len(shape) == 1:  # Biases\n        if shape[0] in [32, 64, 128, 256]:  # Conv biases\n            conv_biases.append((key, shape))\n        else:  # Linear biases\n            linear_biases.append((key, shape))\n    elif len(shape) == 2:  # Linear weights\n        linear_weights.append((key, shape))\n\nprint(f\"Conv3D weights: {len(conv_weights)}\")\nprint(f\"Conv3D biases: {len(conv_biases)}\")\nprint(f\"Linear weights: {len(linear_weights)}\")\nprint(f\"Linear biases: {len(linear_biases)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:31.565525Z","iopub.execute_input":"2025-06-26T13:18:31.565740Z","iopub.status.idle":"2025-06-26T13:18:31.998123Z","shell.execute_reply.started":"2025-06-26T13:18:31.565725Z","shell.execute_reply":"2025-06-26T13:18:31.997510Z"}},"outputs":[{"name":"stdout","text":"Keys in the .npz file:\n['arr_24', 'arr_25', 'arr_26', 'arr_27', 'arr_20', 'arr_21', 'arr_22', 'arr_23', 'arr_28', 'arr_29', 'arr_46', 'arr_47', 'arr_44', 'arr_45', 'arr_42', 'arr_43', 'arr_40', 'arr_41', 'arr_48', 'arr_49', 'arr_54', 'arr_33', 'arr_32', 'arr_31', 'arr_30', 'arr_37', 'arr_36', 'arr_35', 'arr_34', 'arr_39', 'arr_38', 'arr_19', 'arr_18', 'arr_51', 'arr_50', 'arr_53', 'arr_52', 'arr_11', 'arr_10', 'arr_13', 'arr_12', 'arr_15', 'arr_14', 'arr_17', 'arr_16', 'arr_1', 'arr_0', 'arr_3', 'arr_2', 'arr_5', 'arr_4', 'arr_7', 'arr_6', 'arr_9', 'arr_8']\n\nDetailed information:\narr_24: shape=(256,), dtype=float32\n  Value range: [0.080202, 0.262068]\n  Mean: 0.154666, Std: 0.036586\n\narr_25: shape=(256, 256, 3, 3, 3), dtype=float32\n  Value range: [-0.064250, 0.068091]\n  Mean: -0.002131, Std: 0.010475\n\narr_26: shape=(256,), dtype=float32\n  Value range: [-0.056514, 0.071657]\n  Mean: 0.005688, Std: 0.023362\n\narr_27: shape=(256,), dtype=float32\n  Value range: [0.707229, 1.003647]\n  Mean: 0.857945, Std: 0.070124\n\narr_20: shape=(256, 128, 3, 3, 3), dtype=float32\n  Value range: [-0.068121, 0.075156]\n  Mean: -0.000975, Std: 0.013606\n\narr_21: shape=(256,), dtype=float32\n  Value range: [-0.061267, 0.043897]\n  Mean: 0.009260, Std: 0.014019\n\narr_22: shape=(256,), dtype=float32\n  Value range: [0.715295, 0.957261]\n  Mean: 0.856235, Std: 0.048347\n\narr_23: shape=(256,), dtype=float32\n  Value range: [-11.106890, 10.895802]\n  Mean: -1.916007, Std: 5.037821\n\narr_28: shape=(256,), dtype=float32\n  Value range: [-11.011998, 5.644948]\n  Mean: -4.320959, Std: 3.270451\n\narr_29: shape=(256,), dtype=float32\n  Value range: [0.119577, 0.389399]\n  Mean: 0.207126, Std: 0.038105\n\narr_46: shape=(512,), dtype=float32\n  Value range: [-0.048400, 0.059784]\n  Mean: 0.000906, Std: 0.019976\n\narr_47: shape=(512,), dtype=float32\n  Value range: [0.738216, 1.020548]\n  Mean: 0.940745, Std: 0.032809\n\narr_44: shape=(512,), dtype=float32\n  Value range: [0.053721, 0.545000]\n  Mean: 0.138026, Std: 0.049662\n\narr_45: shape=(512, 512), dtype=float32\n  Value range: [-0.162383, 0.165510]\n  Mean: -0.000006, Std: 0.060882\n\narr_42: shape=(512,), dtype=float32\n  Value range: [0.928426, 1.055809]\n  Mean: 0.977398, Std: 0.018922\n\narr_43: shape=(512,), dtype=float32\n  Value range: [-141.741699, 154.638397]\n  Mean: 2.543692, Std: 61.419285\n\narr_40: shape=(38400, 512), dtype=float32\n  Value range: [-0.075171, 0.067345]\n  Mean: 0.000098, Std: 0.010729\n\narr_41: shape=(512,), dtype=float32\n  Value range: [-0.053910, 0.053672]\n  Mean: -0.001420, Std: 0.017684\n\narr_48: shape=(512,), dtype=float32\n  Value range: [-2.385734, 2.299696]\n  Mean: -0.006418, Std: 0.899628\n\narr_49: shape=(512,), dtype=float32\n  Value range: [0.514564, 6.097856]\n  Mean: 1.317718, Std: 0.543557\n\narr_54: shape=(3,), dtype=float32\n  Value range: [0.250576, 0.417308]\n  Mean: 0.320250, Std: 0.070769\n\narr_33: shape=(256,), dtype=float32\n  Value range: [-16.333158, 20.417852]\n  Mean: 1.911303, Std: 9.691635\n\narr_32: shape=(256,), dtype=float32\n  Value range: [0.760223, 0.981358]\n  Mean: 0.896513, Std: 0.039060\n\narr_31: shape=(256,), dtype=float32\n  Value range: [-0.028946, 0.077432]\n  Mean: 0.017620, Std: 0.026014\n\narr_30: shape=(256, 256, 3, 3, 3), dtype=float32\n  Value range: [-0.055048, 0.073165]\n  Mean: 0.000438, Std: 0.011163\n\narr_37: shape=(256,), dtype=float32\n  Value range: [0.867751, 1.037964]\n  Mean: 0.946468, Std: 0.025056\n\narr_36: shape=(256,), dtype=float32\n  Value range: [-0.040070, 0.062812]\n  Mean: 0.004614, Std: 0.017521\n\narr_35: shape=(256, 256, 3, 3, 3), dtype=float32\n  Value range: [-0.064117, 0.063439]\n  Mean: -0.001147, Std: 0.013309\n\narr_34: shape=(256,), dtype=float32\n  Value range: [0.077531, 0.202960]\n  Mean: 0.123398, Std: 0.025895\n\narr_39: shape=(256,), dtype=float32\n  Value range: [0.105915, 0.257011]\n  Mean: 0.151510, Std: 0.023314\n\narr_38: shape=(256,), dtype=float32\n  Value range: [-11.680763, 10.099119]\n  Mean: -2.897492, Std: 4.430123\n\narr_19: shape=(128,), dtype=float32\n  Value range: [0.114614, 0.336974]\n  Mean: 0.197213, Std: 0.043668\n\narr_18: shape=(128,), dtype=float32\n  Value range: [-7.812247, 8.053261]\n  Mean: 0.735328, Std: 3.610930\n\narr_51: shape=(3,), dtype=float32\n  Value range: [-0.129623, 0.204724]\n  Mean: 0.012784, Std: 0.140918\n\narr_50: shape=(512, 3), dtype=float32\n  Value range: [-0.149016, 0.156052]\n  Mean: -0.001755, Std: 0.064957\n\narr_53: shape=(3,), dtype=float32\n  Value range: [-1.092696, -0.117948]\n  Mean: -0.443774, Std: 0.458859\n\narr_52: shape=(3,), dtype=float32\n  Value range: [0.707567, 1.173596]\n  Mean: 0.956051, Std: 0.191509\n\narr_11: shape=(128,), dtype=float32\n  Value range: [-0.033730, 0.014148]\n  Mean: -0.008964, Std: 0.009824\n\narr_10: shape=(128, 64, 3, 3, 3), dtype=float32\n  Value range: [-0.073038, 0.090521]\n  Mean: 0.001861, Std: 0.022040\n\narr_13: shape=(128,), dtype=float32\n  Value range: [-4.707444, 7.481185]\n  Mean: 1.797495, Std: 3.650968\n\narr_12: shape=(128,), dtype=float32\n  Value range: [0.804724, 0.980264]\n  Mean: 0.906358, Std: 0.039389\n\narr_15: shape=(128, 128, 3, 3, 3), dtype=float32\n  Value range: [-0.065775, 0.080167]\n  Mean: 0.000496, Std: 0.017180\n\narr_14: shape=(128,), dtype=float32\n  Value range: [0.132667, 0.454742]\n  Mean: 0.232290, Std: 0.069952\n\narr_17: shape=(128,), dtype=float32\n  Value range: [0.796436, 0.980390]\n  Mean: 0.906835, Std: 0.039396\n\narr_16: shape=(128,), dtype=float32\n  Value range: [-0.049374, 0.028477]\n  Mean: 0.000497, Std: 0.014781\n\narr_1: shape=(32,), dtype=float32\n  Value range: [-0.042803, 0.031045]\n  Mean: -0.007716, Std: 0.017309\n\narr_0: shape=(32, 1, 3, 3, 3), dtype=float32\n  Value range: [-0.137216, 0.136047]\n  Mean: 0.001112, Std: 0.068056\n\narr_3: shape=(32,), dtype=float32\n  Value range: [-0.037273, 0.012146]\n  Mean: -0.001267, Std: 0.011755\n\narr_2: shape=(32,), dtype=float32\n  Value range: [0.922538, 1.048176]\n  Mean: 0.985005, Std: 0.033996\n\narr_5: shape=(64, 32, 3, 3, 3), dtype=float32\n  Value range: [-0.110532, 0.119399]\n  Mean: -0.001033, Std: 0.038834\n\narr_4: shape=(32,), dtype=float32\n  Value range: [1.904131, 16.126888]\n  Mean: 6.839747, Std: 2.645176\n\narr_7: shape=(64,), dtype=float32\n  Value range: [0.918010, 1.020431]\n  Mean: 0.962110, Std: 0.025086\n\narr_6: shape=(64,), dtype=float32\n  Value range: [-0.059311, 0.015582]\n  Mean: -0.019415, Std: 0.017961\n\narr_9: shape=(64,), dtype=float32\n  Value range: [0.161048, 0.582955]\n  Mean: 0.353530, Std: 0.103367\n\narr_8: shape=(64,), dtype=float32\n  Value range: [-5.203263, 3.875864]\n  Mean: -0.536394, Std: 2.371775\n\nConv3D weights: 8\nConv3D biases: 32\nLinear weights: 3\nLinear biases: 12\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Will bring thi into use later if accuracy and other results are not satisfactory\n\n'''\nmean_std_data = np.load(\"/kaggle/input/adnet-normal/mean_std.npz\")\n\nprint(\"Files in mean_std.npz:\")\nprint(mean_std_data.files)\n\n# Load mean and std\nmean = mean_std_data['mean']\nstd = mean_std_data['std']\n\nprint(f\"Mean: {mean}\")\nprint(f\"Std: {std}\")\nprint(f\"Mean shape: {mean.shape}\")\nprint(f\"Std shape: {std.shape}\")\n'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:31.998792Z","iopub.execute_input":"2025-06-26T13:18:31.999019Z","iopub.status.idle":"2025-06-26T13:18:32.004189Z","shell.execute_reply.started":"2025-06-26T13:18:31.999003Z","shell.execute_reply":"2025-06-26T13:18:32.003405Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'\\nmean_std_data = np.load(\"/kaggle/input/adnet-normal/mean_std.npz\")\\n\\nprint(\"Files in mean_std.npz:\")\\nprint(mean_std_data.files)\\n\\n# Load mean and std\\nmean = mean_std_data[\\'mean\\']\\nstd = mean_std_data[\\'std\\']\\n\\nprint(f\"Mean: {mean}\")\\nprint(f\"Std: {std}\")\\nprint(f\"Mean shape: {mean.shape}\")\\nprint(f\"Std shape: {std.shape}\")\\n'"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\nclass ADNet3D(nn.Module):\n    def __init__(self, num_classes=3):\n        super(ADNet3D, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv3d(1, 32, kernel_size=3, padding=1),\n            nn.BatchNorm3d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm3d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm3d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm3d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm3d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm3d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            \n            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm3d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm3d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n        )\n\n        self.adaptive_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(16384, 512),\n            nn.LayerNorm(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            \n            nn.Linear(512, 512),\n            nn.LayerNorm(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            \n            nn.Linear(512, num_classes),\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n'''\ndef load_adnet_weights(model, npz_path):\n    data = np.load(npz_path, allow_pickle=True)\n    \n    # Get all .npz arrays sorted by name\n    npz_arrays = sorted([k for k in data.keys() if k.startswith('arr_')])\n    \n    # Get model parameters in order\n    model_params = list(model.named_parameters())\n    \n    # Match .npz arrays to model parameters by shape\n    mapping = {}\n    used_arrays = set()\n    \n    for param_name, param in model_params:\n        param_shape = tuple(param.shape)\n        \n        # Find .npz array with exact matching shape\n        for arr_key in npz_arrays:\n            if arr_key in used_arrays:\n                continue\n            \n            arr_shape = tuple(data[arr_key].shape)\n            \n            # Create mapping when shapes match exactly\n            if arr_shape == param_shape:\n                mapping[arr_key] = param_name\n                used_arrays.add(arr_key)\n                print(f\"Mapped: {arr_key} → {param_name} (shape: {param_shape})\")\n                break\n    \n    # Load weights into model state_dict\n    state_dict = {}\n    for arr_key, param_name in mapping.items():\n        weight_tensor = torch.from_numpy(data[arr_key]).float()\n        state_dict[param_name] = weight_tensor\n    \n    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n    \n    print(f\"Successfully mapped: {len(mapping)} parameters\")\n    print(f\"Missing keys: {len(missing_keys)}\")\n    \n    return model, len(mapping) > 0\n'''\nmodel = ADNet3D(num_classes=3)\n# model, loading_success = load_adnet_weights(model, \"/kaggle/input/adnet-weights/adnet.npz\")\n# print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:32.005018Z","iopub.execute_input":"2025-06-26T13:18:32.005219Z","iopub.status.idle":"2025-06-26T13:18:32.142973Z","shell.execute_reply.started":"2025-06-26T13:18:32.005197Z","shell.execute_reply":"2025-06-26T13:18:32.142230Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"print(type(model)) \nprint(hasattr(model, 'parameters'))  \nprint(train_df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:32.143744Z","iopub.execute_input":"2025-06-26T13:18:32.143968Z","iopub.status.idle":"2025-06-26T13:18:32.147897Z","shell.execute_reply.started":"2025-06-26T13:18:32.143952Z","shell.execute_reply":"2025-06-26T13:18:32.147308Z"}},"outputs":[{"name":"stdout","text":"<class '__main__.ADNet3D'>\nTrue\nIndex(['subject_id', 'image_id', 'group', 'file_path', 'label'], dtype='object')\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"device = torch.device('cuda') \nmodel = torch.nn.DataParallel(model, device_ids=[0, 1]).to(device)\n\n'''\nfor param in model.module.features.parameters():\n    param.requires_grad = False\nfor param in model.module.classifier.parameters():\n    param.requires_grad = True\n'''\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ndef train_one_epoch(epoch_index):\n    running_loss = 0\n    running_corrects = 0\n    total_samples = 0\n    epoch_corrects = 0\n    epoch_samples = 0\n    \n    for i, data in enumerate(train_loader):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        running_corrects += torch.sum(preds == labels.data)\n        total_samples += labels.size(0)\n        \n        epoch_corrects += torch.sum(preds == labels.data)\n        epoch_samples += labels.size(0)\n        \n        if(i%50==49):\n            last_loss = running_loss/50\n            batch_acc = running_corrects.double() / total_samples\n            print('  batch {} loss: {:.4f} acc: {:.4f}'.format(i + 1, last_loss, batch_acc))\n            running_loss = 0\n            running_corrects = 0\n            total_samples = 0\n\n    return last_loss, epoch_corrects.double() / epoch_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:32.148542Z","iopub.execute_input":"2025-06-26T13:18:32.148724Z","iopub.status.idle":"2025-06-26T13:18:32.179130Z","shell.execute_reply.started":"2025-06-26T13:18:32.148710Z","shell.execute_reply":"2025-06-26T13:18:32.178609Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"EPOCHS = 100\nbest_vloss = 1000000000\nbest_vacc = 0.0\n\nfor epoch in range(EPOCHS):\n    print('EPOCH {}:'.format(epoch + 1))\n    model.train()\n    avg_loss, avg_acc = train_one_epoch(epoch)\n    \n    running_vloss = 0.0\n    running_vcorrects = 0\n    total_vsamples = 0\n    \n    model.eval()\n    with torch.no_grad():\n        for i, vdata in enumerate(val_loader):\n            vinputs, vlabels = vdata\n            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n            voutputs = model(vinputs)\n            vloss = criterion(voutputs, vlabels)\n            running_vloss += vloss.item()\n            \n            _, vpreds = torch.max(voutputs, 1)\n            running_vcorrects += torch.sum(vpreds == vlabels.data)\n            total_vsamples += vlabels.size(0)\n\n    avg_vloss = running_vloss / len(val_loader)\n    avg_vacc = running_vcorrects.double() / total_vsamples\n    print('LOSS train {:.4f} valid {:.4f} ACC train {:.4f} valid {:.4f}'.format(avg_loss, avg_vloss, avg_acc, avg_vacc))\n    if avg_vacc > best_vacc:\n        best_vacc = avg_vacc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:32.179739Z","iopub.execute_input":"2025-06-26T13:18:32.180004Z","execution_failed":"2025-06-26T15:41:33.352Z"}},"outputs":[{"name":"stdout","text":"EPOCH 1:\n  batch 50 loss: 1.2744 acc: 0.4900\n  batch 100 loss: 1.1906 acc: 0.3400\nLOSS train 1.1906 valid 1.2014 ACC train 0.4477 valid 0.2990\nEPOCH 2:\n  batch 50 loss: 1.0849 acc: 0.4800\n  batch 100 loss: 1.1040 acc: 0.4400\nLOSS train 1.1040 valid 1.0913 ACC train 0.4513 valid 0.2990\nEPOCH 3:\n  batch 50 loss: 1.1741 acc: 0.3200\n  batch 100 loss: 1.0829 acc: 0.4400\nLOSS train 1.0829 valid 1.0628 ACC train 0.3971 valid 0.4845\nEPOCH 4:\n  batch 50 loss: 1.0453 acc: 0.4700\n  batch 100 loss: 1.0978 acc: 0.4400\nLOSS train 1.0978 valid 1.0493 ACC train 0.4404 valid 0.4845\nEPOCH 5:\n  batch 50 loss: 1.0308 acc: 0.4800\n  batch 100 loss: 1.2190 acc: 0.4100\nLOSS train 1.2190 valid 1.0587 ACC train 0.4296 valid 0.4845\nEPOCH 6:\n  batch 50 loss: 1.1262 acc: 0.4600\n  batch 100 loss: 1.0967 acc: 0.4700\nLOSS train 1.0967 valid 1.1340 ACC train 0.4765 valid 0.4845\nEPOCH 7:\n  batch 50 loss: 1.1737 acc: 0.3700\n  batch 100 loss: 1.1183 acc: 0.4300\nLOSS train 1.1183 valid 1.0646 ACC train 0.4404 valid 0.4845\nEPOCH 8:\n  batch 50 loss: 1.0976 acc: 0.4500\n  batch 100 loss: 1.0125 acc: 0.5100\nLOSS train 1.0125 valid 1.0498 ACC train 0.4621 valid 0.4845\nEPOCH 9:\n  batch 50 loss: 1.0610 acc: 0.4700\n  batch 100 loss: 1.0745 acc: 0.4600\nLOSS train 1.0745 valid 1.0699 ACC train 0.4585 valid 0.4845\nEPOCH 10:\n  batch 50 loss: 1.0659 acc: 0.4800\n  batch 100 loss: 1.0162 acc: 0.5100\nLOSS train 1.0162 valid 1.0916 ACC train 0.4621 valid 0.2990\nEPOCH 11:\n  batch 50 loss: 1.1100 acc: 0.3500\n  batch 100 loss: 1.0644 acc: 0.4900\nLOSS train 1.0644 valid 1.0420 ACC train 0.4116 valid 0.4845\nEPOCH 12:\n  batch 50 loss: 1.1176 acc: 0.4400\n  batch 100 loss: 1.0135 acc: 0.5500\nLOSS train 1.0135 valid 1.0564 ACC train 0.4765 valid 0.4845\nEPOCH 13:\n  batch 50 loss: 1.1018 acc: 0.4300\n  batch 100 loss: 1.0493 acc: 0.5300\nLOSS train 1.0493 valid 1.0499 ACC train 0.4549 valid 0.4845\nEPOCH 14:\n  batch 50 loss: 1.0802 acc: 0.4400\n  batch 100 loss: 1.0740 acc: 0.4400\nLOSS train 1.0740 valid 1.0609 ACC train 0.4549 valid 0.4845\nEPOCH 15:\n  batch 50 loss: 1.0769 acc: 0.4200\n  batch 100 loss: 1.0589 acc: 0.4300\nLOSS train 1.0589 valid 1.0580 ACC train 0.4513 valid 0.4845\nEPOCH 16:\n  batch 50 loss: 1.0782 acc: 0.4800\n  batch 100 loss: 1.0595 acc: 0.4800\nLOSS train 1.0595 valid 1.0446 ACC train 0.4910 valid 0.4845\nEPOCH 17:\n  batch 50 loss: 1.0014 acc: 0.5300\n  batch 100 loss: 1.1077 acc: 0.4200\nLOSS train 1.1077 valid 1.0468 ACC train 0.4621 valid 0.4845\nEPOCH 18:\n  batch 50 loss: 1.0608 acc: 0.5200\n  batch 100 loss: 1.0716 acc: 0.4100\nLOSS train 1.0716 valid 1.0511 ACC train 0.4729 valid 0.4845\nEPOCH 19:\n  batch 50 loss: 1.0692 acc: 0.4200\n  batch 100 loss: 1.0567 acc: 0.4600\nLOSS train 1.0567 valid 1.0437 ACC train 0.4513 valid 0.4845\nEPOCH 20:\nLOSS train 1.0275 valid 1.0985 ACC train 0.4910 valid 0.2990\nEPOCH 21:\n  batch 50 loss: 1.0726 acc: 0.5100\n  batch 100 loss: 1.0545 acc: 0.4700\nLOSS train 1.0545 valid 1.0453 ACC train 0.4657 valid 0.4845\nEPOCH 22:\n  batch 50 loss: 1.0599 acc: 0.4700\n  batch 100 loss: 1.0127 acc: 0.5200\nLOSS train 1.0127 valid 1.0447 ACC train 0.4729 valid 0.4845\nEPOCH 23:\n  batch 50 loss: 1.1003 acc: 0.4200\n  batch 100 loss: 1.0835 acc: 0.4200\nLOSS train 1.0835 valid 1.0580 ACC train 0.4477 valid 0.4845\nEPOCH 24:\n  batch 50 loss: 1.0241 acc: 0.5300\n  batch 100 loss: 1.0677 acc: 0.4500\nLOSS train 1.0677 valid 1.0561 ACC train 0.4693 valid 0.4845\nEPOCH 25:\n  batch 50 loss: 1.0911 acc: 0.4700\n  batch 100 loss: 1.0262 acc: 0.5200\nLOSS train 1.0262 valid 1.0628 ACC train 0.4657 valid 0.4845\nEPOCH 26:\n  batch 50 loss: 1.0269 acc: 0.4700\n  batch 100 loss: 1.0693 acc: 0.4800\nLOSS train 1.0693 valid 1.0424 ACC train 0.4765 valid 0.4845\nEPOCH 27:\n  batch 50 loss: 1.0427 acc: 0.5000\n  batch 100 loss: 1.0471 acc: 0.5100\nLOSS train 1.0471 valid 1.0499 ACC train 0.4874 valid 0.4845\nEPOCH 28:\n  batch 50 loss: 1.0393 acc: 0.5300\n  batch 100 loss: 1.1348 acc: 0.3000\nLOSS train 1.1348 valid 1.0454 ACC train 0.4440 valid 0.4845\nEPOCH 29:\n  batch 50 loss: 1.0952 acc: 0.3500\n  batch 100 loss: 1.0509 acc: 0.5400\nLOSS train 1.0509 valid 1.0533 ACC train 0.4513 valid 0.4845\nEPOCH 30:\n  batch 50 loss: 1.1433 acc: 0.4200\n  batch 100 loss: 1.0446 acc: 0.4700\nLOSS train 1.0446 valid 1.0694 ACC train 0.4765 valid 0.4845\nEPOCH 31:\n  batch 50 loss: 1.0690 acc: 0.5100\n  batch 100 loss: 1.0716 acc: 0.4500\nLOSS train 1.0716 valid 1.0429 ACC train 0.4729 valid 0.4845\nEPOCH 32:\n  batch 50 loss: 1.0343 acc: 0.4900\n  batch 100 loss: 1.0998 acc: 0.4100\nLOSS train 1.0998 valid 1.0558 ACC train 0.4765 valid 0.4845\nEPOCH 33:\n  batch 50 loss: 1.0110 acc: 0.5200\n  batch 100 loss: 1.0955 acc: 0.4100\nLOSS train 1.0955 valid 1.0423 ACC train 0.4585 valid 0.4845\nEPOCH 34:\n  batch 50 loss: 1.0509 acc: 0.5100\n  batch 100 loss: 1.0782 acc: 0.4400\nLOSS train 1.0782 valid 1.0481 ACC train 0.4801 valid 0.4845\nEPOCH 35:\n  batch 50 loss: 1.0412 acc: 0.4300\n  batch 100 loss: 0.9907 acc: 0.5200\nLOSS train 0.9907 valid 1.0621 ACC train 0.4765 valid 0.4845\nEPOCH 36:\n  batch 50 loss: 0.9988 acc: 0.5400\n  batch 100 loss: 1.0733 acc: 0.4800\nLOSS train 1.0733 valid 1.0446 ACC train 0.4910 valid 0.4845\nEPOCH 37:\n  batch 50 loss: 1.0816 acc: 0.4500\n  batch 100 loss: 1.0409 acc: 0.4800\nLOSS train 1.0409 valid 1.0452 ACC train 0.4838 valid 0.4845\nEPOCH 38:\n  batch 50 loss: 1.0392 acc: 0.4500\n  batch 100 loss: 1.0600 acc: 0.4600\nLOSS train 1.0600 valid 1.0450 ACC train 0.4765 valid 0.4845\nEPOCH 39:\n  batch 50 loss: 1.0831 acc: 0.4600\n  batch 100 loss: 1.0058 acc: 0.5300\nLOSS train 1.0058 valid 1.0412 ACC train 0.4874 valid 0.4845\nEPOCH 40:\n  batch 50 loss: 1.0971 acc: 0.4500\n  batch 100 loss: 1.0127 acc: 0.5200\nLOSS train 1.0127 valid 1.0409 ACC train 0.4910 valid 0.4845\nEPOCH 41:\n  batch 50 loss: 1.0177 acc: 0.5300\n  batch 100 loss: 1.0803 acc: 0.4600\nLOSS train 1.0803 valid 1.0399 ACC train 0.4838 valid 0.4845\nEPOCH 42:\n  batch 50 loss: 1.0147 acc: 0.5100\n  batch 100 loss: 1.0849 acc: 0.5000\nLOSS train 1.0849 valid 1.0436 ACC train 0.4910 valid 0.4845\nEPOCH 43:\n  batch 50 loss: 1.0718 acc: 0.4100\n  batch 100 loss: 1.0572 acc: 0.4600\nLOSS train 1.0572 valid 1.0632 ACC train 0.4765 valid 0.4845\nEPOCH 44:\n  batch 50 loss: 1.0467 acc: 0.5000\n  batch 100 loss: 1.0895 acc: 0.4600\nLOSS train 1.0895 valid 1.0569 ACC train 0.4874 valid 0.4845\nEPOCH 45:\n  batch 50 loss: 1.0838 acc: 0.4600\n  batch 100 loss: 1.0400 acc: 0.4900\nLOSS train 1.0400 valid 1.0426 ACC train 0.4801 valid 0.4845\nEPOCH 46:\n  batch 50 loss: 1.0859 acc: 0.4300\n  batch 100 loss: 1.0232 acc: 0.5200\nLOSS train 1.0232 valid 1.0604 ACC train 0.4874 valid 0.4845\nEPOCH 47:\n  batch 50 loss: 1.0538 acc: 0.4700\n  batch 100 loss: 1.0550 acc: 0.5100\nLOSS train 1.0550 valid 1.0431 ACC train 0.4910 valid 0.4845\nEPOCH 48:\n  batch 50 loss: 1.0391 acc: 0.4400\n  batch 100 loss: 1.0871 acc: 0.4500\nLOSS train 1.0871 valid 1.0485 ACC train 0.4693 valid 0.4845\nEPOCH 49:\n  batch 50 loss: 1.0968 acc: 0.4200\n  batch 100 loss: 0.9876 acc: 0.5700\nLOSS train 0.9876 valid 1.0476 ACC train 0.4910 valid 0.4845\nEPOCH 50:\n  batch 50 loss: 1.0136 acc: 0.5100\n  batch 100 loss: 1.0525 acc: 0.5000\nLOSS train 1.0525 valid 1.0523 ACC train 0.4621 valid 0.4845\nEPOCH 51:\n  batch 50 loss: 1.0575 acc: 0.4700\n  batch 100 loss: 1.0397 acc: 0.5300\nLOSS train 1.0397 valid 1.0518 ACC train 0.4838 valid 0.4845\nEPOCH 52:\n  batch 50 loss: 1.0303 acc: 0.4900\n  batch 100 loss: 1.0282 acc: 0.5100\nLOSS train 1.0282 valid 1.0426 ACC train 0.4838 valid 0.4845\nEPOCH 53:\n  batch 50 loss: 1.0376 acc: 0.5200\n  batch 100 loss: 1.0226 acc: 0.5100\nLOSS train 1.0226 valid 1.0460 ACC train 0.4910 valid 0.4845\nEPOCH 54:\n  batch 50 loss: 1.0794 acc: 0.4200\n  batch 100 loss: 1.0023 acc: 0.5500\nLOSS train 1.0023 valid 1.0495 ACC train 0.4910 valid 0.4845\nEPOCH 55:\n  batch 50 loss: 1.1021 acc: 0.4300\n  batch 100 loss: 1.0350 acc: 0.5100\nLOSS train 1.0350 valid 1.0489 ACC train 0.4910 valid 0.4845\nEPOCH 56:\n  batch 50 loss: 1.0650 acc: 0.4400\n","output_type":"stream"}],"execution_count":null}]}